---
all:
  vars:
    openshift_disable_check: disk_availability,docker_storage,memory_availability,package_version,docker_image_availability
    ansible_ssh_user: root
    deployment_type: openshift-enterprise
    openshift_deployment_type: 'openshift-enterprise'
    openshift_master_api_port: 443
    openshift_master_console_port: 443
    osm_default_node_selector: 'type=compute'
    openshift_docker_options: '--log-driver=json-file --log-opt max-size=50m'

    openshift_release: "3.11"
    openshift_image_tag: "v3.11.43"

    rhsub_pool: {{ rh_pool }}

    domain: {{ domain }}
    oreg_auth_user: !vault
    | 
{{ rh_user_enc }}
    oreg_auth_password: !vault
    | 
{{ rh_pass_enc }}

    # cluster_id is deprecated in favor of openshift_clusterid
    openshift_clusterid: {{ oo_clusterid }}
    openshift_master_cluster_hostname: api.{{ oo_clusterid }}.{{ domain }}
    openshift_master_cluster_public_hostname: {{ oo_clusterid }}.{{ domain }}
    openshift_master_public_api_url: https://{{ oo_clusterid }}.{{ domain }}
    openshift_master_public_console_url: https://{{ oo_clusterid }}.{{ domain }}/console

    # TODO
    os_sdn_network_plugin_name: redhat/openshift-ovs-networkpolicy

    openshift_master_dynamic_provisioning_enabled: true

    osm_custom_cors_origins:
    - console.{{ oo_clusterid }}.{{ domain }}
    - api.{{ oo_clusterid }}.{{ domain }}

    openshift_cloudprovider_kind: aws
    openshift_cloudprovider_aws_access_key: !vault
    | 
{{ aws_access_key_enc }}

    openshift_cloudprovider_aws_secret_key: !vault
    |
{{ aws_secret_key_enc }}

    aws_access_key: !vault
    | 
{{ aws_access_key_enc }}

    aws_secret_key: !vault
    |
{{ aws_secret_key_enc }}

    AWS_SECRET_ACCESS_KEY: !vault
    |
{{ aws_secret_key_enc }}

    AWS_ACCESS_KEY_ID: !vault
    | 
{{ aws_access_key_enc }}

    openshift_master_identity_providers:
    - name: my_htpasswd_provider 
      challenge: true 
      login: true 
      mappingMethod: claim 
      kind: HTPasswdPasswordIdentityProvider

    openshift_master_manage_htpasswd: true

    openshift_master_htpasswd_users: {'{{ htpasswd_username}}': '{{ htpasswd_password }}'}

    openshift_master_named_certificates:
    - keyfile: {{ scf_retval_openshift_key }}
      certfile: {{ scf_retval_openshift_cert }}
      names:
      - {{ oo_clusterid }}.{{ domain }}

    openshift_install_examples: True

    openshift_master_oauth_always_show_provider_selection: False

    # os_firewall_use_firewalld: false
    #osm_cluster_network_cidr:

    # StorageClass Parameters

    # Openshift Router
    openshift_hosted_manage_router: true
    openshift_hosted_router_selector: 'type=infra'
    openshift_hosted_router_replicas: 3

    # openshift_hosted_routers
    openshift_hosted_routers: [{"name": "router", "certificate": {"keyfile": "/tmp/{{ oo_clusterid }}/certs/wildcard.apps.{{ oo_clusterid }}.{{ domain }}.key", "certfile": "/tmp/{{ oo_clusterid }}/certs/wildcard.apps.{{ oo_clusterid }}.{{ domain }}.crt", "cafile": "/tmp/{{ oo_clusterid }}/certs/rootCA.pem"}, "replicas": 3, "serviceaccount": "router", "namespace": "default", "stats_port": 1936, "edits": [{"action": "update", "value": {"name": "ROUTER_USE_PROXY_PROTOCOL", "value": "true"}, "key": "spec.template.spec.containers[0].env"}], "selector": "type=infra", "ports": ["80:80", "443:443"]}]


    # Openshift Registry Console
    # We always install it, this lets us change where it pulls its image from
    osm_use_cockpit: false

    # Openshift Web Console
    openshift_web_console_install: true

    # Openshift Ansible Service Broker
    openshift_ansible_service_broker_install: true

    # Openshift Openshift Service Catalog
    openshift_enable_service_catalog: true
    openshift_service_catalog_image: "registry.redhat.io/openshift3/ose-service-catalog:v3.11.69"

    # Openshift Template Service Broker
    openshift_template_service_broker_install: true
    template_service_broker_selector:
      type: infra

    # Openshift Prometheus
    openshift_cluster_monitoring_operator_install: true
    # FIXME this var is deprecated in favor of openshift_cluster_monitoring_operator_install
    #openshift_hosted_prometheus_deploy: true

    # Not sure if this is needed
    # Openshift Management (CloudForms)
    openshift_management_install_management: false

    # Openshift Logging
    openshift_logging_install_logging: {{ flag_provision_logging }}
    logging_elasticsearch_cluster_size: 3
    openshift_logging_image_version: v3.11

    openshift_logging_kibana_env_vars:
      ELASTICSEARCH_REQUESTTIMEOUT: 600000
    openshift_logging_kibana_nodeselector:
      type: infra

    openshift_logging_curator_memory_limit: 512Mi
    openshift_logging_kibana_memory_limit: 1Gi
    openshift_logging_curator_nodeselector:
      type: infra
    openshift_logging_es_number_of_shards: 1
    openshift_logging_curator_default_days: 14
    openshift_logging_use_ops: False
    openshift_logging_curator_script_log_level: INFO
    openshift_logging_fluentd_cpu_request: 100m
    openshift_logging_es_cluster_size: 3
    openshift_logging_kibana_proxy_memory_limit: 256Mi
    openshift_logging_es_pvc_dynamic: True
    openshift_logging_es_number_of_replicas: 1
    openshift_logging_es_pvc_size: 500Gi
    openshift_logging_elasticsearch_kibana_index_mode: shared_ops
    openshift_logging_fluentd_nodeselector:
      logging-infra-fluentd: "true"
    openshift_logging_kibana_cpu_request: 25m
    openshift_logging_kibana_replica_count: 1
    openshift_logging_fluentd_hosts: []
    openshift_logging_kibana_proxy_cpu_request: 25m
    openshift_logging_fluentd_memory_limit: 512Mi
    openshift_logging_curator_log_level: WARN
    openshift_logging_es_memory_limit: 12Gi
    openshift_logging_es_cpu_request: 375m
    openshift_logging_curator_cpu_request: 25m
    openshift_logging_es_nodeselector:
      type: infra
    openshift_logging_elasticsearch_proxy_memory_limit: 256Mi

    
    # Openshift Metrics
    openshift_metrics_cassandra_storage_type: dynamic
    #openshift_metrics_hawkular_hostname: metrics.{{ oo_clusterid }}.{{ domain }}
    openshift_metrics_install_metrics: {{ flag_provision_metrics }}
    openshift_metrics_start_cluster: 'true'
    openshift_metrics_startup_timeout: 500
    openshift_metrics_hawkular_limits_memory: 3Gi
    openshift_metrics_heapster_limits_memory: 3.75Gi
    openshift_metrics_resolution: 30s
    openshift_metrics_project: openshift-infra
    openshift_metrics_hawkular_nodeselector:
      type: infra
    openshift_metrics_heapster_requests_memory: 3.75Gi
    openshift_metrics_cassandra_limits_memory: 4Gi
    openshift_metrics_cassandra_replicas: 3
    openshift_metrics_heapster_standalone: False
    openshift_metrics_hawkular_requests_memory: 3Gi
    openshift_metrics_heapster_requests_cpu: 100m
    openshift_metrics_duration: 7
    openshift_metrics_cassandra_requests_cpu: 375m
    openshift_metrics_cassandra_requests_memory: 4Gi
    openshift_metrics_cassandra_nodeselector:
      type: infra
    openshift_metrics_hawkular_requests_cpu: 100m
    openshift_metrics_heapster_nodeselector:
      type: infra
    openshift_metrics_cassandra_pvc_size: 100Gi
    openshift_metrics_hawkular_replicas: 1

    # ------------------------ #
    # Common/Cluster Variables #
    # ------------------------ #

    # specify a clusterid
    # This value is also used as the default value for many other components.
    openshift_aws_clusterid: "{{ oo_clusterid }}"

    # AWS region
    # This value will instruct the plays where all items should be created.
    # Multi-region deployments are not supported using these plays at this time.
    openshift_aws_region: "{{ oo_sublocation }}"

    openshift_aws_create_iam_role: true

    openshift_aws_create_dns: true
    openshift_aws_custom_dns_provider_role: "{{ g_play_dns_role_path }}"
    openshift_aws_dns_provider: "custom"
    openshift_aws_dns_zone: "{{ domain }}"

    openshift_master_bootstrap_auto_approve: true

    openshift_master_default_subdomain: apps.{{ oo_clusterid }}.{{ domain }}

    # --- #
    # VPC #
    # --- #

    # openshift_aws_create_vpc defaults to true.  If you don't wish to provision
    # a vpc, set this to false.
    #openshift_aws_create_vpc: true

    # openshift_aws_vpc
    # Thi creates the "openshift_aws_vpc" variable
    openshift_aws_vpc: {"subnets": {"{{ oo_sublocation }}": [{"cidr": "172.31.0.0/21", "az": "{{ oo_sublocation }}a"}]}, "cidr": "172.31.0.0/16", "name": "{{ oo_clusterid }}"}

    # Name of the vpc.  Needs to be set if using a pre-existing vpc.
    #openshift_aws_vpc_name: "{{ oo_clusterid }}"

    # Name of the subnet in the vpc to use.  Needs to be set if using a pre-existing
    # vpc + subnet. Otherwise will use the subnet with 'default_az' set (see above
    # example VPC structure)
    #openshift_aws_subnet_az:

    # -------------- #
    # Security Group #
    # -------------- #

    # openshift_aws_create_security_groups defaults to true.  If you wish to use
    # an existing security group, set this to false.
    openshift_aws_create_security_groups: true

    # openshift_aws_build_ami_group is the name of the security group to build the
    # ami in.  This defaults to the value of openshift_aws_clusterid.
    #openshift_aws_build_ami_group: "{{ oo_clusterid }}"

    openshift_aws_base_ami: "ami-056a4552e1bf40119"

    # openshift_aws_launch_config_security_groups specifies the security groups to
    # apply to the launch config.  The launch config security groups will be what
    # the cluster actually is deployed in.
    #openshift_aws_launch_config_security_groups: see roles/openshift_aws/defaults.yml

    # openshift_aws_node_security_groups are created when
    # openshift_aws_create_security_groups is set to true.
    #openshift_aws_node_security_groups: see roles/openshift_aws/defaults.yml

    # -------- #
    # ssh keys #
    # -------- #

    # Specify the key pair name here to connect to the provisioned instances.  This
    # can be an existing key, or it can be one of the keys specified in
    # openshift_aws_users
    openshift_aws_ssh_key_name: towerProvisioner_key

    # -- #
    # S3 #
    # -- #

    # Create an s3 bucket.
    #openshift_aws_create_s3: True

    openshift_aws_s3_bucket_name: {{ oo_clusterid }}-3scale

    # Backups
    cluster_backup_bucket_name: "qecicd-cert-backups"
    cluster_backup_integreatly_bucket_name: "{{ oo_clusterid }}-integreatly-backups"
    cluster_backup_namespace: openshift-integreatly-backups
    cluster_backup_secret_name: s3-credentials


    # --- #
    # ELB #
    # --- #


    # custom certificates are required for the ELB
    openshift_aws_iam_cert_name: {{ oo_clusterid }}

    # todo certs
    openshift_aws_iam_cert_path: "{{ scf_retval_openshift_cert }}"
    openshift_aws_iam_cert_chain_path: "{{ scf_retval_chain_cert }}"
    openshift_aws_iam_cert_key_path: "{{ scf_retval_openshift_key }}" 

    # oa_* vars are vars that we create so we don't have to copy everything around
    oa_default_openshift_node_group_edits:
    - key: kubeletArguments.system-reserved
      value:
      - 'cpu=1000m,memory=1Gi'
    - key: kubeletArguments.image-gc-high-threshold
      value:
      - '80'
    - key: kubeletArguments.image-gc-low-threshold
      value:
      - '60'
    - key: kubeletArguments.maximum-dead-containers
      value:
      - '50'
    - key: kubeletArguments.maximum-dead-containers-per-container
      value:
      - '2'
    - key: kubeletArguments.minimum-container-ttl-duration
      value:
      - 5m

    openshift_node_groups:
    - name: node-config-master
      labels:
      - 'node-role.kubernetes.io/master=true'
      - 'type=master'
      - "region={{ oo_sublocation }}"
      - 'logging-infra-fluentd=true'
      edits: "{{ '{{' }} oa_default_openshift_node_group_edits {{ '}}' }}"
    - name: node-config-infra
      labels:
      - 'node-role.kubernetes.io/infra=true'
      - 'type=infra'
      - "region={{ oo_sublocation }}"
      - 'logging-infra-fluentd=true'
      - 'config_pod=true'
      edits: "{{ '{{' }} oa_default_openshift_node_group_edits {{ '}}' }}"
    - name: node-config-compute
      labels:
      - 'node-role.kubernetes.io/compute=true'
      - 'type=compute'
      - "region={{ oo_sublocation }}"
      - 'logging-infra-fluentd=true'
      - 'config_pod=true'
      edits: "{{ '{{' }} oa_default_openshift_node_group_edits {{ '}}' }}"

    openshift_aws_node_groups:
    - name: "{{ oo_clusterid }} Compute"
      group: compute
      node_group_config: node-config-compute
      tags:
        host-type: node
        sub-host-type: compute
        runtime: docker
        scalegroup: 'True'
        config: 'False'
    - name: "{{ oo_clusterid }} Infra"
      group: infra
      node_group_config: node-config-infra
      tags:
        host-type: node
        sub-host-type: infra
        runtime: docker
        scalegroup: 'True'
        config: 'False'

    openshift_aws_master_instance_config:
      instance_type: {{ master_instance_size }}
      volumes: "{{ '{{' }} openshift_aws_master_volumes {{ '}}' }}"
      health_check: "{{ '{{' }} openshift_aws_scale_group_health_check {{ '}}' }}"
      exact_count: {{ openshift_aws_master_group_desired_size | default(3) }}
      termination_policy: "{{ '{{' }} openshift_aws_node_group_termination_policy {{ '}}' }}"
      iam_role: "{{ '{{' }} openshift_aws_launch_config_iam_roles['master'].name {{ '}}' }}"
      elbs: "{{ '{{' }} openshift_aws_elb_dict | json_query('master.[*][0][*].name') {{ '}}' }}"
      groups:
      - "{{ oo_clusterid }}"  # default sg
      - "{{ oo_clusterid }}_master"  # node type sg
      - "{{ oo_clusterid }}_master_k8s"  # node type sg k8s

    openshift_aws_master_volumes:
    - device_name: /dev/sda1
      volume_size: 100
      volume_type: gp2
      delete_on_termination: False
    - device_name: /dev/sdb
      volume_size: 200
      volume_type: gp2
      delete_on_termination: False

    # This is default, but added the "config" tag to enable config loop
    openshift_aws_master_group:
    - name: "{{ oo_clusterid }} master group"
      group: master
      node_group_config: node-config-master
      tags:
        host-type: master
        sub-host-type: default
        runtime: docker
        config: "{{ '{{' }} 'False' | string {{ '}}' }}"

    openshift_aws_node_group_config:
      compute:
        instance_type: {{ compute_instance_size }}
        volumes: "{{ '{{' }} openshift_aws_node_group_config_node_volumes {{ '}}' }}"
        health_check:
          period: 60
          type: EC2
        min_size: {{ openshift_aws_compute_group_min_size | default(2) }}
        max_size: {{ openshift_aws_compute_group_desired_size|int * 3 }}
        desired_size: {{ openshift_aws_compute_group_desired_size }}
        termination_policy: "{{ '{{' }} openshift_aws_node_group_termination_policy {{ '}}' }}"
        replace_all_instances: "{{ '{{' }} openshift_aws_node_group_replace_all_instances {{ '}}' }}"
        iam_role: "{{ '{{' }} openshift_aws_launch_config_iam_roles['compute'].name {{ '}}' }}"
      infra:
        instance_type: {{ infra_instance_size }}
        volumes: "{{ '{{' }} openshift_aws_node_group_config_node_volumes {{ '}}' }}"
        health_check:
          period: 60
          type: EC2
        min_size: {{ openshift_aws_infra_group_min_size | default(2) }}
        max_size: {{ openshift_aws_infra_group_desired_size|int * 3 }}
        desired_size: {{ openshift_aws_infra_group_desired_size }}
        termination_policy: "{{ '{{' }} openshift_aws_node_group_termination_policy {{ '}}' }}"
        replace_all_instances: "{{ '{{' }} openshift_aws_node_group_replace_all_instances {{ '}}' }}"
        iam_role: "{{ '{{' }} openshift_aws_launch_config_iam_roles['infra'].name {{ '}}' }}"
        elbs: "{{ '{{' }} openshift_aws_elb_dict | json_query('infra.[*][0][*].name') {{ '}}' }}"

    openshift_aws_node_group_config_node_volumes:
    - device_name: /dev/sda1
      volume_size: 100
      device_type: gp2
      delete_on_termination: True
    - device_name: /dev/sdb
      volume_size: 200
      device_type: gp2
      delete_on_termination: True

    openshift_aws_launch_config_security_groups:
      master:
      - "{{ oo_clusterid }}"  # default sg
      - "{{ oo_clusterid }}_master"  # node type sg
      - "{{ oo_clusterid }}_master_k8s"  # node type sg k8s
      compute:
      - "{{ oo_clusterid }}"  # default sg
      - "{{ oo_clusterid }}_compute"  # node type sg
      - "{{ oo_clusterid }}_compute_k8s"  # node type sg k8s
      infra:
      - "{{ oo_clusterid }}"  # default sg
      - "{{ oo_clusterid }}_infra"  # node type sg
      - "{{ oo_clusterid }}_infra_k8s"  # node type sg k8s
      compute-crio:
      - "{{ oo_clusterid }}"  # default sg
      - "{{ oo_clusterid }}_compute"  # node type sg
      - "{{ oo_clusterid }}_compute_k8s"  # node type sg k8s

    openshift_aws_ami: {{ g_play_image_id }}

    openshift_aws_ami_map:
      master: "{{ '{{' }} openshift_aws_ami {{ '}}' }}"
      infra: "{{ '{{' }} openshift_aws_ami {{ '}}' }}"
      compute: "{{ '{{' }} openshift_aws_ami {{ '}}' }}"

    openshift_aws_node_user_data: |
      {{ '{%' }} if l_instance_tags['host-type'] == 'master' {{ '%}' }}
      #cloud-config
      write_files:
      - path: /root/openshift_bootstrap/openshift_settings.yaml
        owner: 'root:root'
        permissions: '0640'
        content: |
          openshift_node_config_name: node-config-master

      runcmd:
      - [ ansible-playbook, /root/openshift_bootstrap/bootstrap.yml]
      {{ '{%' }}  else {{ '%}' }}
      #cloud-config
      write_files:
      - path: /root/openshift_bootstrap/openshift_settings.yaml
        owner: 'root:root'
        permissions: '0640'
        content: |
          openshift_node_config_name: "{{ '{{' }} openshift_aws_node_group.node_group_config {{ '}}' }}"
      - path: /etc/origin/node/bootstrap.kubeconfig
        owner: 'root:root'
        permissions: '0640'
        encoding: b64
        content: "{{ '{{' }} openshift_aws_launch_config_bootstrap_token | b64encode {{ '}}' }}"

      runcmd:
      - [ ansible-playbook, /root/openshift_bootstrap/bootstrap.yml]
      - [ systemctl, restart, systemd-hostnamed]
      - [ systemctl, restart, NetworkManager]
      - [ systemctl, enable, atomic-openshift-node]
      - [ systemctl, start, atomic-openshift-node]
      {{ '{%' }} if 'infra' in openshift_aws_node_group.node_group_config {{ '%}' }}
      - [ /root/sre_firstboot_scripts/infra-elasticsearch-sysctl.sh]
      {{ '{%' }}  endif {{ '%}' }}
      {{ '{%' }}  endif {{ '%}' }}
